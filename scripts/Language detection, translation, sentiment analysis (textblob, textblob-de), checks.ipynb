{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful scripts for working with post data \n",
    "### Language detection and translation with Google and DeepL \n",
    "### Sentiment analysis with textblob and textblob-de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# language detection, uses Google\n",
    "# Due to API limits pause 1 sec after every iteration\n",
    "\n",
    "from textblob_de import TextBlobDE as TextBlob\n",
    "from tqdm.notebook import tqdm\n",
    "import time \n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    blob = TextBlob(\"Der Park ist wunderschön im Frühling!\")\n",
    "\n",
    "    blob.detect_language()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of German sentiment analysis textblob-de with pandas. Shows poor results.\n",
    "import pandas as pd \n",
    "df = pd.read_excel(\"posts.xlsx\") # rows with post texts and language\n",
    "df\n",
    "\n",
    "def sentim(text):\n",
    "    blob = TextBlobDE(text)\n",
    "    return blob.sentiment\n",
    "\n",
    "# sentim(\"ich liebe dich\") # Sentiment(polarity=1.0, subjectivity=0.0)\n",
    "df[\"polarity\"] = 999\n",
    "df[\"subjectivity\"] = 999\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    if row[\"language\"] == \"de\":\n",
    "        try: \n",
    "            currblob = sentim(row.plaintext)\n",
    "            df.loc[index,\"polarity\"] = currblob[0]\n",
    "            df.loc[index,\"subjectivity\"] = currblob[1]\n",
    "        except:\n",
    "            print(\"failed at \"+ index)\n",
    "\n",
    "# few phrases recognized, often false sentiment analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google translation from any language to English\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def gtrans(text):\n",
    "    try:\n",
    "        transl = translator.translate(text)\n",
    "        return transl.text\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "df[\"GoogleEN\"] = \"\"\n",
    "for index, row in tqdm(df.iterrows()): # normally don´t use iterrows due to performance issues. Used here for quick error handling\n",
    "    try:\n",
    "        df.loc[index,\"GoogleEN\"] = gtrans(row[\"plaintext\"])\n",
    "    except:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepL offers an API but would be overkill for this project\n",
    "# Simply use Deepl's document translator\n",
    "# i.e. a word document: every post with a new line\n",
    "# Afterwards create a txt file and read in Python\n",
    "\n",
    "f = open(r\"deepl_korrektur_output.txt\", encoding=\"utf-8\").read()\n",
    "f\n",
    "\n",
    "# after let's create a pandas dataframe\n",
    "allposts = []\n",
    "for i in tqdm(range(111)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    \n",
    "    splitter2 = \"\\n\"+str(i)\n",
    "    splitter1 = \"\\n\"+str(i-1)\n",
    "    allposts.append(f.split(splitter1)[1].split(splitter2)[0].replace(\"\\n\",\"\").replace(\"\\t\",\"\"))\n",
    "\n",
    "df = pd.DataFrame({'col':allposts})\n",
    "df.to_excel(\"deepl_tranlsation.xlsx\")\n",
    "\n",
    "# concat and check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis with textblob\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "def senten(text):\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentiment\n",
    "    except:\n",
    "        return [99,99]\n",
    "\n",
    "# for Google's tranlsation\n",
    "df[\"SentENpolGoogle\"] = 0\n",
    "df[\"SentENsubGoogle\"] = 0\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    currsen = senten(row[\"GoogleEN\"])\n",
    "    df.loc[index,\"SentENpolGoogle\"] = currsen[0]\n",
    "    df.loc[index,\"SentENsubGoogle\"] = currsen[1]\n",
    "    \n",
    "# same for DeepL\n",
    "df[\"SentENpolDeepL\"] = 0\n",
    "df[\"SentENsubDeepL\"] = 0\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    currsen = senten(row[\"DeepLEN\"])\n",
    "    df.loc[index,\"SentENpolDeepL\"] = currsen[0]\n",
    "    df.loc[index,\"SentENsubDeepL\"] = currsen[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify sentiment values to ordinal scale: positive, neutral, negative or unclassifiable\n",
    "def posneg(text):\n",
    "    if text == 0:\n",
    "        return \"neutral\"\n",
    "    if text == 99:\n",
    "        return \"unclassifiable\"\n",
    "    if text < 0:\n",
    "        return \"negative\"\n",
    "    if text > 0:\n",
    "        return \"positive\"\n",
    "        \n",
    "df[\"Sentiment_Google\"] = df.SentENpolGoogle.apply(lambda x: posneg(x))\n",
    "df[\"Sentiment_Deepl\"] = df.SentENpolDeepL.apply(lambda x: posneg(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if different translation led to same sentiments \n",
    "\n",
    "df[\"equal_sentiment\"] = True\n",
    "df[\"final_sentiment\"] = df[\"Sentiment_Google\"]\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    # only if not equal\n",
    "    if row[\"Sentiment_Google\"] != row[\"Sentiment_Deepl\"]:\n",
    "        \n",
    "        # if one is neutral take the other\n",
    "        if row[\"Sentiment_Google\"] == \"neutral\":\n",
    "            df.loc[index,\"final_sentiment\"] =  row[\"Sentiment_Deepl\"]\n",
    "        if row[\"Sentiment_Deepl\"] == \"neutral\":\n",
    "            df.loc[index,\"final_sentiment\"] =  row[\"Sentiment_Google\"]\n",
    "        \n",
    "        # if one is unclassifiable take the other\n",
    "        if row[\"Sentiment_Google\"] == \"unclassifiable\":\n",
    "            df.loc[index,\"final_sentiment\"] =  row[\"Sentiment_Deepl\"]\n",
    "        if row[\"Sentiment_Deepl\"] == \"unclassifiable\":\n",
    "            df.loc[index,\"final_sentiment\"] =  row[\"Sentiment_Google\"]\n",
    "            \n",
    "        df.loc[index,\"equal_sentiment\"] = False\n",
    "\n",
    "# check some results i.e. with some loc conditions\n",
    "tf = df.loc[df.Sentiment_Google ==\"unclassifiable\"]\n",
    "tf.loc[tf.equal_sentiment == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one more check: if post is other than English even after translation return unclassifiable\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    if row[\"language\"] != \"en\":\n",
    "        df.loc[index,\"final_sentiment\"] =  \"unclassifiable\"\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
